\section{Related Work}
 In this section we discuss areas of research that are pertinent to our work.

\subsection{Configuration Complexity} 

Perhaps the most relevant work on this topic is done by Benson \textit{et al} 2009. In this paper, the authors develop a family of complexity models and metrics that describe the complexity of the design and configuration of an enterprise network.They describe three key metrics for measuring the complexity of designing networks: referential complexity, inherent complexity, and router roles. Referential complexity is the measure of the number of reference links from one router to other routers in the network. Inherent complexity tries to measure how policies dictating the function of a router impact the performance of the network. However, the metric most pertaining to our work is router roles. The authors recognized that while creating a network, the operators will define a base set of behaviours that will be present across all routers in the control plane. They proceed to argue that networks become more complex to manage as router roles increase and as routers start to play multiple roles. As we have mentioned before in this paper’s introduction, a common cause for network outages is configuration errors, which stem from the complexity of the network. If we can facilitate the building of new configurations, then perhaps we can also help reduce common mistakes. Highly complex routing designs leave more opportunity for configuration errors to occur~\cite{cutting-edge} which, as we mentioned in our introduction, are the leading cause for network outages.

\subsection{Code Completion Tools}
There are many code completion engines for software codebases. We gave a brief overview in Section 2 but here we go into a little detail about how they work.\\

Kaiser \textit{et al.} 1988 was one of the earliest works done on auto-completion for code. The authors present an architecture that provides intelligent assistance by automating certain tasks like compiling or completing missing parameters to a function. The assistant maintains of a database of all the entities in the software system, such as modules, procedures, types etc., and a comprehensive collection of rules that define the conditions in which the assistant tools may carry out a possible task. Overall, the architecture presented in this paper takes a rule-based approach reminiscent of expert systems. If a rule is not implemented by the developers, then the engine is unable to provide any assistance. This architecture seems as a precursor to modern software development technologies which offer much of the same assistance. IDEs such as IntelliJ and Eclipse also offer tab completion, which ranks all possible completions from the invocation point in alphabetical order. These IDEs often use type inference to collect all possible methods available to a certain variable. \\

Robbes \textit{et al.} 2008 and Bruch \textit{et al.} 2009 showcase how program history can be used for maintaining a model of existing code. They store information about changes made in groups of work that are written close together in time. The researchers used various algorithmic techniques to generate code completions. Usually, these algorithms employ some form of variable contextualization. Robbes \textit{et al.} 2008 makes use of static type inference with a clever session based history which first finds similar code segments and then recommends what was written in the same time frame. Bruch \textit{et al.} 2009 on the other hand, extracts the context of variables and encodes them as a feature vector for those particular variables. Features may include the type of the variable, methods already invoked on it, the method in which it is called etc. Their algorithm (which is similar to KNN) can then use these feature matrices along with the input context from the user to retrieve possible recommendations which are determined by their distances from the input vector.  Completion techniques involving program histories offer fairly respectable accuracy results but come with their idiosyncrasies.\\  

\subsection{Configuration Synthesis} 

In recent years, researchers have developed network configuration synthesis tools that tackle the problem of generating network-wide configurations. These tools can build router configurations entirely from scratch by using high level policies the owning organization wants to enforce, which are provided by network operators as input. Configuration synthesizers can be extremely useful to avoid bugs, guarantee policy compliance, and sometimes even offer network resilience.\\ 

SyNET~\cite{synet} and Zeppelin are two prominent examples of such tools. SyNet accomplishes this by modeling the routing protocols as a stratified Datalog program, and synthesizing inputs such that they satisfy certain policies or path requirements that comply with the operator’s requirements. Zeppelin on the other hand, employs a two phase solution: first synthesizing policy compliant paths, and then generating configurations guided by those concrete paths. Zeppelin offers increased connectivity resilience over configurations generated by SyNet as minimizing the number of static routes used in the configurations. There are other tools such as Propane and Cocoon that similarly use high level specification to generate low level configurations, though we did not study them extensively.\\
 
These systems demonstrate that it is possible to use policy constraints to guide configuration creation.  However, they require well-defined and thorough policies to be made by the operators, which may be a tedious task for larger networks. Additionally, depending on the complexity of the networks and the policies , synthesis from scratch can take long periods of time and would have to be repeated whenever a new policy is introduced or an existing one is changed. Finally, these systems require the replacement of the entire current network control plane, which can incur significant overhead and network downtime.\\

It is perhaps possible for these systems to be used in conjunction with code completion techniques to provide a specialized network configuration completion engine. It would require us to develop some intermediate system between the policy definitions and the synthesis techniques proposed by SyNet and Zeppelin. For now, we simply consider configuration synthesis as a potential area to explore future improvement to our engine. 

