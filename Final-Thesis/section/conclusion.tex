\documentclass[../thesis.tex]{subfiles}
\begin{document}

\chapter{Conclusion}
\label{ch:conclusion}

Compared to software developers, network operators are often left neglected when it comes to development tools. Our work tries to bridge that gap by providing a simple completion engine that could be incorporated into a more extensive tool. Our initial findings show that we can get fairly respectable accuracies with an off-the-shelf NLP technique. We provide analyses that help legitimize the potential of such a model to be used in a completion engine. Additionally, we propose a myriad of refinements to the model that could potentially improve our accuracies to desirable numbers.

\section{Future Work}
There are many directions in which we can expand on this work. An obvious next step would be to incorporate higher order N-gram models (quadgrams, 5-grams etc.) in to our engine and test their accuracies. Larger N-grams could help suggest complete statements which would be extremely useful for minimizing input from the network operators. Furthermore, when using N-gram models, researchers will often start at a higher number and fallback on lower order N-grams. For example, we could first use the trigram model to generate suggestions, and if the results are unsatisfactory we could invoke the bigram model. A combination of the two results should result in improved performance. It should also be relatively easy to add additional placeholders in the preprocessing step, such as for VLAN numbers and routing costs. Additionally, we acknowledge that we have limited ourselves to N-gram models as we deemed it an excellent starting point. However, it is imperative for us to explore other code completion and NLP techniques (such as Recurrent Neural Networks) before we can confidently declare N-grams as the final choice for our engine. In doing so, we also leave open the possibility of developing a hybrid model which offers the best of individual ones.\\

As we mentioned earlier in Section 3, there are some techniques that we could explore to generate custom completions for IP addresses and subnets. Currently, the model will generate all the addresses that it has seen before during training. It would be possible to improve these results if we could store a mapping of all the subnets that the router is known to be connected to. Then if a network operator wants to add an IP address we would be able to suggest only those addresses that are relevant to that particular router.\\

One extremely useful addition to the model would be context awareness. We could generate customized completions for different stanza types in the configuration files. For example, a routing interface stanza uses certain keyword like neighbor and network, more often than other stanzas. Our engine should then weight these keywords higher if it is invoked within a routing stanza. Existing configuration parsers like Batfish~\cite{batfish} already have the functionality to be context-aware of stanzas. We would like to explore ways in which we can extract information using such parsers and incorporate it into our engine.\\ 

Lastly, we have additional plans for further evaluating our model. It should be relatively straightforward to train and test on router configurations belonging to non-academic organizations. It should be possible to scrape additional ones from online data sources such as router vendor documentations and publicly available Internet configurations. Additionally, we would like to ascertain the extent to which our model is generalizable. This would require multiple analyses across configurations that vary in owners, device types, size etc. This will allow us to see whether our model is confounded when tested on sources that are different in nature to the training set.tion{Future Work}

\end{document}