\section{Introduction}

A network's backbone is its routing control plane: a set of rules and distributed routing protocols that describe how the network should operate. A control plane is thus defined through configuration files present on every individual routing device in the network. These configurations are written in vendor specific languages (e.g. Cisco IOS and Juniper Junos) and describe very low level behaviours of a particular router. Network operators tasked to configure control planes are required to satisfy various `policies' that the owning organization wants to enforce: e.g certain devices should always be blocked from communicating with higher privileged devices.\\

Research has shown that configuring control planes can be extremely complex in modern networks~\cite{complexity}. Consequently, this causes configurations to be prone to errors, many of which are only uncovered during operation after a failure has already dealt significant damage~\cite{errors}.â€¯For example, in 2012, failure of a router in a Microsoft Azure data center triggered previously unknown configuration errors on other devices, degrading service in the West Europe region for over two hours~\cite{azure}. Additionally, surveys done by researchers in the past~\cite{Zeng} have shown that network administrators report router/switch software bugs as the most common symptoms of network failure. These examples highlight a need to develop highly resilient configurations that perform reliably.\\  

There are three main areas of research that are trying to enable this resilience: configuration synthesis, configuration development tools and network verification. Synthesis tools like NetComplete [CITE], Zeppelin [CITE] and SyNet [CITE] are working towards perhaps the most ambitious solution: automatically generating all configurations in one batch. However, all synthesis tools require comprehensive input from the network operators. They usually have to fully specify the high level requirements of the policies the organization wishes to impose, ahead of time. This can be a time consuming and nuanced task for the operators. It is difficult to ascertain what existing policies the network follows and there is a lot of room to miss some rule or policy. Additionally, they may also be limited by the expressiveness of the language being used to describe the policies. \textbf{EXAMPLE}This high-input nature of synthesis systems make them much more suitable during the initial stages of developing a network, given that the operators are willing to put in the work. However, the return rate of configuration synthesis falls sharply if the network operators are concerned with incremental changes. If there is a new router to be added to the network, the operators will need to reevaluate all policies in accordance of this new router. Additionally, the synthesis system will generate configurations for the entire network regardless of whether a router needs to be updated or not. This can make synthesis a unnecessarily resource wasteful process as all routers have to be updated, which may lead to more downtime in the network.\\ 

In contrast, network verification and repair (e.g ARC~\cite{arc}) can be extremely useful to determine whether the current configurations comply with the existing policies of the network. Again, these policies could be defined by the operators or, as in the case of ARC, they could be inferred via a snapshot of the network. However, verification by design is a post development tool i-e it will catch errors after they have already been produced. It does not help operators avoid producing these errors in the first place. The network operators may be given a suggested fix by these verification tools but they may not be human readable. For example ARC will use a Max-SMT solver to generate a fix, however the network operators will be left to their own devices to interpret the resulting boolean algebra. In essence, the operators will have to retrace the error and manually edit the faulty configurations. We thus wish to explore a solution that sits in between configuration synthesis and verification.\\

% Connect these two paragraphs in a better
One existing approach that can be utilized by network operators in the middle of the development lifecycle is templating. Currently, operators try to minimize extraneous work by reusing existing configurations that have been known to work in the past. When creating a network, operators typically write templates containing specific configuration lines that define a base set of behaviours for different router roles~\cite{complexity}. These templates are then used to specialize individual routers to achieve objectives for their respective part of the network. Due to varying router specifications, the template systems used allow network operators to fill in parameters with appropriate information each time the template is used. However, in practice, as the customer requirements of the organization change over time the networks start to get more complex. [BENSON] describes how configuration templates in use constantly grow in number and become increasingly specialized as a service grows and as customer requirements evolve. The paper shows how operators will have to write up new templates or edit existing ones eventually. We envision our engine would ease this process by providing convenient suggestions while operators are editing configurations (regardless of whether they are templates or not).
Our approach thus serves to complement existing techniques for writing routing configurations.\\ 

The analyses on two campus networks performed by [KIM] shed light on how networks evolve. If we consider the types of changes that operators perform, we observe some homogeneity. Not only are many changes security related but, each campus has distinct security practices that use specific router configuration commands. This seems to hold true across organizations, where certain design and operational practices tend to be followed. Thus, a completion engine could exploit this regularity by learning from a history of changes and suggest the routines and practices that an organization tends to follow. Our penultimate goal would be a "writing assistant" for network configurations, one that can complete entire stanzas (explained in section 2.1) and recommend more concise syntax. It could also proactively offer negative recommendations. If the operator attempts to change a line or stanza of the network configuration that is not frequently changed, the system could discourage the modification by alerting the operator. We postulate that developing an effective token recommendation system would be a concrete first step towards such a goal.\\

We consider the problem of writing network configurations to be analogous to writing software code. Most configurations are written using vendor specific languages, that make use of rules and keywords similar to traditional programming languages. We envision an interactive system inspired by code completion engines that could be invoked by network operators as they are writing router configurations to offer them suggestions for what to put in next, or list the options available from the invocation point.\\

Recent research on software systems has shown that codebases tend to contain regularities, much like natural languages~\cite{naturalness}. This has motivated further research on using traditional Natural Language Processing techniques for code completion and token suggestion, resulting in fairly accurate models~\cite{naturalness, raychev}. We hypothesize a similar regularity for network configurations, especially since they tend to be homogeneous by design, reusing the same set of keywords/tokens. Our analysis of router configurations from a large research university showed that configurations shared between 85\% and 99\% of tokens across different routers, which seems to support our claim. This prompted us to explore simple NLP techniques that could leverage these token similarities to produce useful suggestions or completions.\\

Another reason we gravitated towards NLP as a basis of our model is the flexibility it entails. Traditional code-completion techniques capitalize on the grammar rules of the languages to build their models. An analogous version for network configurations would require us to reverse engineer the configuration grammar, presumably exploiting some existing parser.\footnote{In fact, we tried to extract this information ourselves, hoping to compare our model to tab-completion which seemed as a reasonable ground truth to try and improve on. However, accurately parsing the parse tree proved to be a tedious, time consuming process. We eventually had to drop this line of analysis, as we were unable to get the system to a point where we were satisfied by the tab-completion output.}
Moreover, as different vendors have different grammars, we would effectively have to repeat this process for every vendor and ostensibly rebuild the engine. On the other hand, an NLP approach is theoretically language agnostic. For example, in this paper we perform tests on Cisco configurations but, we could easily train and test the model on configurations written for Juniper. Conceding that it is almost exclusively data dependent, we maintain that an NLP model is a good candidate for an elegant solution to the token completion problem. We thus consider our work as a feasibility analysis for this particular strategy. In general, our results show that using an off-the-shelf NLP algorithm with minor modifications, can give us up to 93\% accuracy for some configurations. These are encouraging results and in Section [results] we discuss some additional analyses we performed that make us optimistic about the utility of this approach.\\

This paper outlines the necessary details for building a completion engine for network configurations. Section 2 provides background information about network configurations, existing network management tools and code completion techniques. Section 3 describes our token analysis results and explains how our model works. Section 4 discusses our plans for extending the model. Finally, Section 5 reviews all the work pertinent to our research, followed by a conclusion in Section 6.

