\section{Future Work}
There are many directions in which we can take this work. An obvious next step would be to test the accuracy of our trigram models. When using N-gram models, researchers will often start at a higher number and fallback on lower order N-grams. To that effect, we could first use the trigram model to generate suggestions, and if the results are unsatisfactory we could invoke the bigram model. A combination of the two results should result in improved performance. It should also be relatively easy to add additional placeholders in the preprocessing step, such as for VLAN numbers and interface numbers.\\

As we mentioned earlier in the Preliminary Work section, there are some techniques that we could explore to generate custom completions for IP addresses and subnets. Currently, the model will generate all the addresses that it has seen before during training. It would be possible to improve these results if we could store a mapping of all the subnets that the router is known to be connected to. Then if a network operator wants to add an IP address we would be able to suggest only those addresses that are relevant to that particular router.\\

One extremely useful addition to the model would be context awareness. We could generate customized completions for different stanza types in the configuration files. For example, a routing interface stanza uses certain keyword like neighbor and network, more often than other stanzas. Our engine should then weight these keywords higher if it is invoked within a routing stanza. Existing configuration parsers like Batfish~\cite{batfish} already have the functionality to be context-aware of stanzas. We would like to explore ways in which we can extract information using such parsers and incorporate it into our engine.\\ 

Lastly, we have additional plans for evaluating our model. It should be relatively straightforward to train and test on real-world configurations. We already have access to a dataset from two universities and it should be simple to scrape additional ones from online data sources such as router vendor documentations and publicly available Internet configurations. Additionally, we would like to ascertain the extent to which our model is generalizable. This would require multiple analyses across configurations that vary with time, owners, device types etc. This will allow us to see whether our model is confounded when tested on sources that are different in nature to the training set. 